{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b9a6090",
   "metadata": {},
   "source": [
    "### This notebook generates the moisture-CAPE joint distributions for MCSs in the reanalysis-convective tracking data. First import libraries and constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "627df270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy.ma as ma\n",
    "import seaborn as sns\n",
    "import scipy.optimize\n",
    "from matplotlib import cm\n",
    "from numpy import unravel_index\n",
    "\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "from plotting_utilities import *\n",
    "from thermodynamic_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0ec6c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 9.8 # gravitational acceleration [m s-2]\n",
    "rho_air = 1.395 # density of air (kg m-3)\n",
    "rho_water = 1000 #density of water (kg m-3)\n",
    "eps = 0.01802/0.02897 # ratio of MW_water to MW_air"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f84a20d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-56.0\n",
      "56.0\n",
      "(278407,)\n",
      "(89404,)\n"
     ]
    }
   ],
   "source": [
    "# array of years\n",
    "years = np.arange( 1983, 2008 )\n",
    "\n",
    "# create list of file names\n",
    "file_years = file_concatenator(years)\n",
    "\n",
    "# Are we only looking at tropical MCSs?\n",
    "minlat_array = nc_open_compile(file_years,\"min latitude\")\n",
    "print(np.nanmin(minlat_array))\n",
    "maxlat_array = nc_open_compile(file_years,\"max latitude\")\n",
    "print(np.nanmax(maxlat_array))\n",
    "pmax_array = nc_open_compile(file_years,\"pmax\")\n",
    "cape_array = nc_open_compile(file_years,\"cape\")\n",
    "\n",
    "tropical_indx = np.argwhere( (minlat_array >= -10) & (maxlat_array <= 10) & (cape_array > 10))[:,0]\n",
    "tropical_rain_indx = np.argwhere( (minlat_array >= -10) & (maxlat_array <= 10) &\n",
    "                                  (pmax_array >= np.percentile(pmax_array,75)) & (cape_array > 10) )[:,0]\n",
    "print(tropical_indx.shape)\n",
    "print(tropical_rain_indx.shape)\n",
    "\n",
    "# applying same for MCS lifetime and morphology\n",
    "lifetime_array = nc_open_compile(file_years,\"lifetime\")\n",
    "lifetime_ERAI = negative_to_nan(lifetime_array)[tropical_rain_indx]\n",
    "rad_array = nc_open_compile(file_years,\"rad\")\n",
    "rad_ERAI = negative_to_nan(rad_array)[tropical_rain_indx]\n",
    "ctt_array = nc_open_compile(file_years,\"ctt\")\n",
    "ctt_ERAI = negative_to_nan(ctt_array)[tropical_rain_indx]\n",
    "maxrad_array = nc_open_compile(file_years,\"maxrad\")\n",
    "maxrad_ERAI = negative_to_nan(maxrad_array)[tropical_rain_indx]\n",
    "minctt_array = nc_open_compile(file_years,\"minctt\")\n",
    "minctt_ERAI = negative_to_nan(minctt_array)[tropical_rain_indx]\n",
    "cape_ERAI = negative_to_nan(cape_array)[tropical_rain_indx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a7a06e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min, Mean, and Max SD [g kg-1]: -5.236998778535022 1.999890760787415 9.222317067703118\n"
     ]
    }
   ],
   "source": [
    "#pressure level values converted into double point precision\n",
    "#factor of 100 converts hPa to Pa. we want to use SI units exclusively below.\n",
    "plev_ERAI = np.double((xr.open_dataset(file_years[0])).pressure.data)*100\n",
    "\n",
    "# calculate the saturation vapor mixing ratio, Curry & Webster (4.37)\n",
    "temp_ERAI = nc_open_compile( file_years, \"temperature\", 'stack' )[tropical_rain_indx]\n",
    "qvsat_ERAI = eps * satVapP_liq(temp_ERAI) / ( plev_ERAI - satVapP_liq(temp_ERAI) )\n",
    "\n",
    "# extract pressure from the data files\n",
    "# water vapour levels opened and vstacked, negatives removed\n",
    "qv_array = nc_open_compile( file_years, \"qv\", 'stack' )\n",
    "qv_ERAI = negative_to_nan(qv_array)[tropical_rain_indx]\n",
    "\n",
    "# as in Singh et al. 2017 we calculate saturation deficit as the arithmetic mean\n",
    "# between its values at 850, 700, and 550 hPa\n",
    "i = np.argmin( np.abs(plev_ERAI - 85000) )\n",
    "sd850_ERAI = (qvsat_ERAI[:,i] - qv_ERAI[:,i])*1000   # 1000 converts [kg kg-1] to [g kg-1]\n",
    "#sd850pre_ERAI = (qvsat_ERAI[:,i] - qvpre6_ERAI[:,i])*1000\n",
    "i = np.argmin( np.abs(plev_ERAI - 70000) )\n",
    "sd700_ERAI = (qvsat_ERAI[:,i] - qv_ERAI[:,i])*1000\n",
    "#sd700pre_ERAI = (qvsat_ERAI[:,i] - qvpre6_ERAI[:,i])*100\n",
    "i = np.argmin( np.abs(plev_ERAI - 55000) )\n",
    "sd550_ERAI = (qvsat_ERAI[:,i] - qv_ERAI[:,i])*1000\n",
    "#sd550pre_ERAI = (qvsat_ERAI[:,i] - qvpre6_ERAI[:,i])*1000\n",
    "\n",
    "sd_ERAI = (sd850_ERAI + sd700_ERAI + sd550_ERAI)/3\n",
    "#sdpre_ERAI = (sd850pre_ERAI + sd700pre_ERAI + sd550pre_ERAI)/3\n",
    "print( 'Min, Mean, and Max SD [g kg-1]: ' + str(np.nanmin(sd_ERAI)) + ' ' + str(np.nanmedian(sd_ERAI)) + ' ' + str(np.nanmax(sd_ERAI)) )"
   ]
  },
  {
   "cell_type": "raw",
   "id": "98d121d0",
   "metadata": {},
   "source": [
    "#pressure level values converted into double point precision\n",
    "#factor of 100 converts hPa to Pa. we want to use SI units exclusively below.\n",
    "plev_ERAI = np.double((xr.open_dataset(file_years[0])).pressure.data)*100\n",
    "\n",
    "# calculate the saturation vapor mixing ratio, Curry & Webster (4.37)\n",
    "temp_ERAI = nc_open_compile( file_years, \"temperature\", 'stack' )[tropical_rain_indx]\n",
    "qvsat_ERAI = eps * satVapP_liq(temp_ERAI) / ( plev_ERAI - satVapP_liq(temp_ERAI) )\n",
    "\n",
    "# extract pressure from the data files\n",
    "# water vapour levels opened and vstacked, negatives removed\n",
    "qv_array = nc_open_compile( file_years, \"qv\", 'stack' )\n",
    "qv_ERAI = negative_to_nan(qv_array)[tropical_rain_indx]\n",
    "\n",
    "# as in Singh et al. 2017 we calculate saturation deficit as the arithmetic mean\n",
    "# between its values at 850, 700, and 550 hPa\n",
    "i = np.argmin( np.abs(plev_ERAI - 85000) )\n",
    "sf850_ERAI = qvsat_ERAI[:,i]/qvsat_ERAI[:,i]*100.\n",
    "i = np.argmin( np.abs(plev_ERAI - 70000) )\n",
    "sf700_ERAI = qv_ERAI[:,i]/qvsat_ERAI[:,i]*100.\n",
    "i = np.argmin( np.abs(plev_ERAI - 55000) )\n",
    "sf550_ERAI = qv_ERAI[:,i]/qvsat_ERAI[:,i]*100.\n",
    "\n",
    "sf_ERAI = (sf850_ERAI + sf700_ERAI + sf550_ERAI)/3\n",
    "print( 'Min, Mean, and Max SD [g kg-1]: ' + str(np.nanmin(sf_ERAI)) + ' ' + str(np.nanmedian(sf_ERAI)) + ' ' + str(np.nanmax(sf_ERAI)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac55e6e",
   "metadata": {},
   "source": [
    "### Joint distribution of 1-SF_LT and CAPE filtering by morphology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5dde3a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# binning for saturation deficit\n",
    "#xbins1 = np.linspace( 20, 100, 40 )\n",
    "xbins1 = np.linspace( 0, 5, 30 )\n",
    "ybins1 = np.logspace( 1.7, 3.5, 40 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a5001d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the 25th percentile of lifetime to define 'short-lived' (3 hours)\n",
    "i = np.where( lifetime_ERAI <= np.percentile( lifetime_ERAI, 25 ) )\n",
    "sd_ERAI_young = sd_ERAI[i]\n",
    "cape_ERAI_young = cape_ERAI[i]\n",
    "i = np.where( (~np.isnan(sd_ERAI_young)) & (~np.isnan(cape_ERAI_young)) )\n",
    "h1 = np.histogram2d( sd_ERAI_young[i], cape_ERAI_young[i], bins=[xbins1, ybins1] )\n",
    "\n",
    "# Find the 75th percentile of lifetime to define 'long-lived' (11 hours)\n",
    "i = np.where( lifetime_ERAI >= np.percentile( lifetime_ERAI, 75 ) )\n",
    "sd_ERAI_old = sd_ERAI[i]\n",
    "cape_ERAI_old = cape_ERAI[i]\n",
    "i = np.where( (~np.isnan(sd_ERAI_old)) & (~np.isnan(cape_ERAI_old)) )\n",
    "h2 = np.histogram2d( sd_ERAI_old[i], cape_ERAI_old[i], bins=[xbins1, ybins1] )\n",
    "\n",
    "# Find the 25th percentile of extent to define 'small' (132 km)\n",
    "i = np.where( maxrad_ERAI <= np.percentile( maxrad_ERAI, 25) )\n",
    "sd_ERAI_small = sd_ERAI[i]\n",
    "cape_ERAI_small = cape_ERAI[i]\n",
    "i = np.where( (~np.isnan(sd_ERAI_small)) & (~np.isnan(cape_ERAI_small)) )\n",
    "h3 = np.histogram2d( sd_ERAI_small[i], cape_ERAI_small[i], bins=[xbins1, ybins1] )\n",
    "i = np.where( rad_ERAI <= np.percentile( rad_ERAI, 25) )\n",
    "sd_ERAI_small = sd_ERAI[i]\n",
    "cape_ERAI_small = cape_ERAI[i]\n",
    "i = np.where( (~np.isnan(sd_ERAI_small)) & (~np.isnan(cape_ERAI_small)) )\n",
    "h3a = np.histogram2d( sd_ERAI_small[i], cape_ERAI_small[i], bins=[xbins1, ybins1] )\n",
    "\n",
    "# Find the 75th percentile of extent to define 'large' (400 km)\n",
    "i = np.where( maxrad_ERAI >= np.percentile( maxrad_ERAI, 75) )\n",
    "sd_ERAI_big = sd_ERAI[i]\n",
    "cape_ERAI_big = cape_ERAI[i]\n",
    "i = np.where( (~np.isnan(sd_ERAI_big)) & (~np.isnan(cape_ERAI_big)) )\n",
    "h4 = np.histogram2d( sd_ERAI_big[i], cape_ERAI_big[i], bins=[xbins1, ybins1] )\n",
    "i = np.where( rad_ERAI > np.percentile( rad_ERAI, 75) )\n",
    "sd_ERAI_big = sd_ERAI[i]\n",
    "cape_ERAI_big = cape_ERAI[i]\n",
    "i = np.where( (~np.isnan(sd_ERAI_big)) & (~np.isnan(cape_ERAI_big)) )\n",
    "h4a = np.histogram2d( sd_ERAI_big[i], cape_ERAI_big[i], bins=[xbins1, ybins1] )\n",
    "\n",
    "# Find the 25th percentile of CTT to define 'deep' (188 K)\n",
    "i = np.where( minctt_ERAI <= np.percentile( minctt_ERAI, 25 ) )\n",
    "sd_ERAI_deep = sd_ERAI[i]\n",
    "cape_ERAI_deep = cape_ERAI[i]\n",
    "i = np.where( (~np.isnan(sd_ERAI_deep)) & (~np.isnan(cape_ERAI_deep)) )\n",
    "h5 = np.histogram2d( sd_ERAI_deep[i], cape_ERAI_deep[i], bins=[xbins1, ybins1] )\n",
    "\n",
    "# Find the 75th percentile of CTT to define 'shallow' (201 K)\n",
    "i = np.where(minctt_ERAI >= np.percentile( minctt_ERAI, 75 ))\n",
    "sd_ERAI_shallow = sd_ERAI[i]\n",
    "cape_ERAI_shallow = cape_ERAI[i]\n",
    "i = np.where( (~np.isnan(sd_ERAI_shallow)) & (~np.isnan(cape_ERAI_shallow)) )\n",
    "h6 = np.histogram2d( sd_ERAI_shallow[i], cape_ERAI_shallow[i], bins=[xbins1, ybins1] )"
   ]
  },
  {
   "cell_type": "raw",
   "id": "404145cf",
   "metadata": {},
   "source": [
    "# Find the 25th percentile of lifetime to define 'short-lived' (3 hours)\n",
    "i = np.where( lifetime_ERAI <= np.percentile( lifetime_ERAI, 25 ) )\n",
    "sf_ERAI_young = sf_ERAI[i]\n",
    "cape_ERAI_young = cape_ERAI[i]\n",
    "i = np.where( (~np.isnan(sf_ERAI_young)) & (~np.isnan(cape_ERAI_young)) )\n",
    "h1 = np.histogram2d( sf_ERAI_young[i], cape_ERAI_young[i], bins=[xbins1, ybins1] )\n",
    "\n",
    "# Find the 75th percentile of lifetime to define 'long-lived' (11 hours)\n",
    "i = np.where( lifetime_ERAI >= np.percentile( lifetime_ERAI, 75 ) )\n",
    "sf_ERAI_old = sf_ERAI[i]\n",
    "cape_ERAI_old = cape_ERAI[i]\n",
    "i = np.where( (~np.isnan(sf_ERAI_old)) & (~np.isnan(cape_ERAI_old)) )\n",
    "h2 = np.histogram2d( sf_ERAI_old[i], cape_ERAI_old[i], bins=[xbins1, ybins1] )\n",
    "\n",
    "# Find the 25th percentile of extent to define 'small' (132 km)\n",
    "i = np.where( maxrad_ERAI <= np.percentile( maxrad_ERAI, 25) )\n",
    "sf_ERAI_small = sf_ERAI[i]\n",
    "cape_ERAI_small = cape_ERAI[i]\n",
    "i = np.where( (~np.isnan(sf_ERAI_small)) & (~np.isnan(cape_ERAI_small)) )\n",
    "h3 = np.histogram2d( sf_ERAI_small[i], cape_ERAI_small[i], bins=[xbins1, ybins1] )\n",
    "i = np.where( rad_ERAI <= np.percentile( rad_ERAI, 25) )\n",
    "sf_ERAI_small = sf_ERAI[i]\n",
    "cape_ERAI_small = cape_ERAI[i]\n",
    "i = np.where( (~np.isnan(sf_ERAI_small)) & (~np.isnan(cape_ERAI_small)) )\n",
    "h3a = np.histogram2d( sf_ERAI_small[i], cape_ERAI_small[i], bins=[xbins1, ybins1] )\n",
    "\n",
    "# Find the 75th percentile of extent to define 'large' (400 km)\n",
    "i = np.where( maxrad_ERAI >= np.percentile( maxrad_ERAI, 75) )\n",
    "sf_ERAI_big = sf_ERAI[i]\n",
    "cape_ERAI_big = cape_ERAI[i]\n",
    "i = np.where( (~np.isnan(sf_ERAI_big)) & (~np.isnan(cape_ERAI_big)) )\n",
    "h4 = np.histogram2d( sf_ERAI_big[i], cape_ERAI_big[i], bins=[xbins1, ybins1] )\n",
    "i = np.where( rad_ERAI > np.percentile( rad_ERAI, 75) )\n",
    "sf_ERAI_big = sf_ERAI[i]\n",
    "cape_ERAI_big = cape_ERAI[i]\n",
    "i = np.where( (~np.isnan(sf_ERAI_big)) & (~np.isnan(cape_ERAI_big)) )\n",
    "h4a = np.histogram2d( sf_ERAI_big[i], cape_ERAI_big[i], bins=[xbins1, ybins1] )\n",
    "\n",
    "# Find the 25th percentile of CTT to define 'deep' (188 K)\n",
    "i = np.where( minctt_ERAI <= np.percentile( minctt_ERAI, 25 ) )\n",
    "sf_ERAI_deep = sf_ERAI[i]\n",
    "cape_ERAI_deep = cape_ERAI[i]\n",
    "i = np.where( (~np.isnan(sf_ERAI_deep)) & (~np.isnan(cape_ERAI_deep)) )\n",
    "h5 = np.histogram2d( sf_ERAI_deep[i], cape_ERAI_deep[i], bins=[xbins1, ybins1] )\n",
    "\n",
    "# Find the 75th percentile of CTT to define 'shallow' (201 K)\n",
    "i = np.where(minctt_ERAI >= np.percentile( minctt_ERAI, 75 ))\n",
    "sf_ERAI_shallow = sf_ERAI[i]\n",
    "cape_ERAI_shallow = cape_ERAI[i]\n",
    "i = np.where( (~np.isnan(sf_ERAI_shallow)) & (~np.isnan(cape_ERAI_shallow)) )\n",
    "h6 = np.histogram2d( sf_ERAI_shallow[i], cape_ERAI_shallow[i], bins=[xbins1, ybins1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c080af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "font_size = 18\n",
    "def scatter_hist(x, y, xbins, ybins, ax, ax_histx, ax_histy):\n",
    "    # no labels\n",
    "    ax_histx.tick_params(axis=\"x\", labelbottom=False)\n",
    "    ax_histy.tick_params(axis=\"y\", labelleft=False)\n",
    "\n",
    "    # the scatter plot:\n",
    "    h = ax.hist2d( x, y, bins=(xbins, ybins), cmap=cm.Blues )\n",
    "    wgts = np.ones_like(x)/float(len(x))*100\n",
    "    ax_histx.hist(x, bins=xbins, edgecolor='k', weights=wgts )\n",
    "    ax_histx.tick_params(axis='both', which='major', labelsize=font_size-5)\n",
    "    wgts = np.ones_like(y)/float(len(y))*100\n",
    "    ax_histy.hist(y, bins=ybins, edgecolor='k', weights=wgts, orientation='horizontal')\n",
    "    ax_histy.tick_params(axis='both', which='major', labelsize=font_size-5)\n",
    "    #ax_histy.set_yscale('log')\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03554078",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_61518/2363789804.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4.75\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m plt.rcParams.update({\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m'font.size'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfont_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m'axes.labelsize'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfont_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m'xtick.labelsize'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfont_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fig = plt.figure( figsize=(4.75,5) )\n",
    "plt.rcParams.update({\n",
    "    'font.size':font_size,\n",
    "    'axes.labelsize':font_size,\n",
    "    'xtick.labelsize':font_size,\n",
    "    'ytick.labelsize':font_size,\n",
    "    'legend.fontsize':font_size,\n",
    "})\n",
    "gs = fig.add_gridspec( 2, 2, width_ratios=(4, 1), height_ratios=(1, 4), left=0.1, right=0.9, bottom=0.1, top=0.9,\n",
    "                     wspace=0.05, hspace=0.05 )\n",
    "ax = fig.add_subplot( gs[1,0] )\n",
    "ax_histx = fig.add_subplot( gs[0,0], sharex=ax )\n",
    "ax_histy = fig.add_subplot( gs[1,1], sharey=ax )\n",
    "\n",
    "## main panel a\n",
    "i = np.where( (~np.isnan(sd_ERAI)) & (~np.isnan(cape_ERAI)) & (cape_ERAI > 10) )\n",
    "scatter_hist( sd_ERAI[i], cape_ERAI[i], xbins1, ybins1, ax, ax_histx, ax_histy )\n",
    "#ax.set_xticks( [20, 40, 60, 80] )\n",
    "ax_histx.set_ylabel( 'prob [%]', fontsize=font_size-5 )\n",
    "ax_histx.set_yticks( [0, 2.5, 5, 7.5, 10], rotation=45 )\n",
    "ax_histy.set_xlabel( 'prob [%]', fontsize=font_size-5 )\n",
    "ax_histy.set_xticks( [0, 2.5, 5], rotation=45 )\n",
    "ax.set_ylabel( r'MCS CAPE [J kg$^{-1}$]' )\n",
    "ax.set_xlabel( r'Saturation deficit '\n",
    "              '\\n'\n",
    "              '[g kg$^{-1}$]' )\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylim([100,2500])\n",
    "##\n",
    "\n",
    "## Where is the center of mass of the joint distribution for young/old/big/small systems? \n",
    "# (The cells below must be run for this.)\n",
    "h_csfpmax = [ h3, h4, h5, h6, h1, h2 ]\n",
    "farbe = [ 'gold', 'darkorange', 'turquoise', 'lawngreen', 'red', 'pink' ]\n",
    "forme = [ 'o', 'o', 'D', 'D', 's', 's' ]\n",
    "##grose = [ 200, 200, 200, 200, 200, 200 ]\n",
    "for i, histo, f, s in zip( np.arange(8), h_csfpmax, farbe, forme ):\n",
    "    l, m = unravel_index( histo[0].argmax(), histo[0].shape )\n",
    "    ax.scatter( xbins1[l], ybins1[m], marker=s, color=f, s=150, zorder=5, edgecolor='k', alpha=0.8 )\n",
    "    if i%2 == 0:\n",
    "        ll, mm = unravel_index( h_csfpmax[i+1][0].argmax(), h_csfpmax[i+1][0].shape )\n",
    "        ax.plot( [xbins1[l], xbins1[ll]], [ybins1[m], ybins1[mm]], lw=3, color=f, zorder=10 )\n",
    "\n",
    "for a in ax, ax_histx, ax_histy:\n",
    "    a.spines['top'].set_visible( False )\n",
    "    a.spines['right'].set_visible( False )\n",
    "    for t in a.get_yticklabels():\n",
    "        t.set_rotation(45)\n",
    "\n",
    "plt.tight_layout()\n",
    "#fig.savefig( '/groups/sylvia/JAS-MCS-rain/figures/sd-cape-joint-ERAI.pdf', bbox_inches='tight' )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5e4aa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ncplot",
   "language": "python",
   "name": "ncplot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
